# CV-Praktikum

## Summary of Most Important Papers

| Category | Paper Title | Year | Conference | Keywords and Phrases | Link |
|----------|-------------|------|------------|----------------------|------|
| **Language-based Image Segmentation** | **PhraseCut: Language-based Image Segmentation in the Wild** | 2020 | CVPR | Image Segmentation, Language, Vision | [Link](https://ieeexplore.ieee.org/document/9157191) |
| **Applications** | **Object-Independent Human-to-Robot Handovers Using Real-Time Robotic Vision** | 2021 | IEEE RA Letters | Robotic Vision, Human-Robot Interaction, Real-Time | [Link](https://ieeexplore.ieee.org/document/9206048) |
| **Deep Learning** | **Deep Multimodal Learning: A Survey on Recent Advances and Trends** | 2017 | IEEE Signal Processing Magazine | Multimodal Learning, Deep Learning, Survey | [Link](https://ieeexplore.ieee.org/document/8103116) |
| **Speech Recognition** | **Listen, Attend and Spell: A Neural Network for Large Vocabulary Conversational Speech Recognition** | 2016 | ICASSP | Speech Recognition, Neural Networks, ASR | [Link](https://ieeexplore.ieee.org/document/7472621) |
| **Speech Recognition** | **SpecAugment: A Simple Data Augmentation Method for Automatic Speech Recognition** | 2019 | Interspeech | Speech Recognition, Data Augmentation, ASR | [Link](http://dx.doi.org/10.21437/Interspeech.2019-2680) |
| **Speech Recognition** | **Conformer: Convolution-Augmented Transformer for Speech Recognition** | 2020 | Interspeech | Speech Recognition, Transformers, Convolution | [Link](https://www.isca-archive.org/interspeech_2020/gulati20_interspeech.pdf) |
| **Speech Recognition** | **A Comparative Study on E-Branchformer vs Conformer in Speech Recognition, Translation, and Understanding Tasks** | 2023 | Interspeech | Speech Recognition, Transformers, Comparison Study | [Link](https://arxiv.org/abs/2305.11073) |
| **Visual Grounding** | **Joint Visual Grounding and Tracking with Natural Language Specification** | 2023 | CVPR | Visual Grounding, Tracking, Natural Language | [Link](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhou_Joint_Visual_Grounding_and_Tracking_With_Natural_Language_Specification_CVPR_2023_paper.pdf) |
| **Visual Grounding** | **SeqTR: A Simple yet Universal Network for Visual Grounding** | 2022 | ECCV | Visual Grounding, Universal Network, Vision | [Link](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136950593.pdf) |
| **Referring Image Segmentation** | **GRES: Generalized Referring Expression Segmentation** | 2023 | CVPR | Referring Expression, Segmentation, Vision | [Link](https://openaccess.thecvf.com/content/CVPR2023/papers/Liu_GRES_Generalized_Referring_Expression_Segmentation_CVPR_2023_paper.pdf) |
| **Referring Image Segmentation** | **Beyond One-to-One: Rethinking the Referring Image Segmentation** | 2023 | CVPR | Referring Image Segmentation, Vision, One-to-One | [Link](https://openaccess.thecvf.com/content/ICCV2023/papers/Hu_Beyond_One-to-One_Rethinking_the_Referring_Image_Segmentation_ICCV_2023_paper.pdf) |
| **Referring Expression Segmentation** | **Meta Compositional Referring Expression Segmentation** | 2023 | CVPR | Referring Expression, Segmentation, Meta-Learning | [Link](https://openaccess.thecvf.com/content/CVPR2023/papers/Xu_Meta_Compositional_Referring_Expression_Segmentation_CVPR_2023_paper.pdf) |
| **Open-Vocabulary Image Segmentation** | **Open-Vocabulary Panoptic Segmentation with Text-to-Image Diffusion Models** | 2023 | CVPR | Panoptic Segmentation, Diffusion Models, Text-to-Image | [Link](https://openaccess.thecvf.com/content/CVPR2023/papers/Xu_Open-Vocabulary_Panoptic_Segmentation_With_Text-to-Image_Diffusion_Models_CVPR_2023_paper.pdf) |
| **Referring Image Segmentation** | **Bridging Vision and Language Encoders: Parameter-Efficient Tuning for Referring Image Segmentation** | 2023 | CVPR | Referring Image Segmentation, Vision, Language Encoders | [Link](https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_Bridging_Vision_and_Language_Encoders_Parameter-Efficient_Tuning_for_Referring_Image_ICCV_2023_paper.pdf) |
